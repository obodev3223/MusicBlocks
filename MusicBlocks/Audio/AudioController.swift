//
//  AudioController.swift
//  MusicBlocks
//
//  Created by Jose R. Garc칤a on 7/3/25.
//

import AudioKit
import AudioKitEX
import AVFoundation
import SoundpipeAudioKit

protocol AudioControllerDelegate: AnyObject {
    func audioController(_ controller: AudioController, didDetectNote note: String, frequency: Float, amplitude: Float, deviation: Double)
    func audioControllerDidDetectSilence(_ controller: AudioController)
}

class AudioController: ObservableObject {
    static let sharedInstance = AudioController()
    weak var delegate: AudioControllerDelegate?
    
    @Published var tunerData: TunerEngine.TunerData = .inactive
    @Published var stabilityDuration: TimeInterval = 0
    
    private let tunerEngine = TunerEngine.shared
    
    let engine = AudioEngine()
    var pitchTap: PitchTap!
    var mic: AudioEngine.InputNode!
    var silence: Fader!
    
    // Umbrales y configuraci칩n
    private let minimumAmplitude: Float = 0.02
    private let minimumFrequency: Float = 20.0
    private let maximumFrequency: Float = 2000.0
    private let stabilityThreshold: Float = 3.0 // Variaci칩n m치xima permitida en Hz
    private let amplitudeSmoothing: Float = 0.9 // Factor de suavizado para la amplitud
    
    // Variables de seguimiento
    private var lastStableFrequency: Float = 0
    private var stabilityStartTime: Date?
    private var smoothedAmplitude: Float = 0
    private var lastProcessedTime: Date = Date()
    private let minimumProcessingInterval: TimeInterval = 0.05 // 50ms entre procesamientos
    
    private func updateStability(frequency: Float) {
        if abs(frequency - lastStableFrequency) <= stabilityThreshold {
            if stabilityStartTime == nil {
                stabilityStartTime = Date()
            }
            stabilityDuration = Date().timeIntervalSince(stabilityStartTime ?? Date())
        } else {
            lastStableFrequency = frequency
            stabilityStartTime = nil
            stabilityDuration = 0
        }
    }
    
    private func processPitchData(frequency: Float, amplitude: Float) {
        // Suavizar la amplitud
        self.smoothedAmplitude = (self.amplitudeSmoothing * self.smoothedAmplitude) + ((1 - self.amplitudeSmoothing) * amplitude)
        
        // Verificar si ha pasado suficiente tiempo desde el 칰ltimo procesamiento
        let currentTime = Date()
        guard currentTime.timeIntervalSince(lastProcessedTime) >= minimumProcessingInterval else {
            return
        }
        lastProcessedTime = currentTime
        
//        print("游꿗 Procesando audio - Freq: \(frequency), Amp: \(self.smoothedAmplitude)") // Aqu칤 tambi칠n necesita self
        
        // Verificar condiciones para procesar el pitch
        if self.smoothedAmplitude > minimumAmplitude { // Aqu칤 est치 el error, necesitamos self
            if frequency >= minimumFrequency && frequency <= maximumFrequency {
                let tunerData = tunerEngine.processPitch(
                    frequency: frequency,
                    amplitude: self.smoothedAmplitude
                )
                DispatchQueue.main.async {
                    self.tunerData = tunerData
                    print("游꿧 Nota detectada: \(tunerData.note)")
                    self.delegate?.audioController(
                        self,
                        didDetectNote: tunerData.note,
                        frequency: frequency,
                        amplitude: self.smoothedAmplitude,
                        deviation: tunerData.deviation
                    )
                }
                updateStability(frequency: frequency)
            }
        } else {
            DispatchQueue.main.async {
                self.tunerData = .inactive
                self.stabilityDuration = 0
  //              print("游댆 Silencio detectado")
                self.delegate?.audioControllerDidDetectSilence(self)
            }
        }
    }
    
    private init() {
        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord,
                                                          options: [.defaultToSpeaker, .mixWithOthers])
            try AVAudioSession.sharedInstance().setActive(true)
            
            guard let input = engine.input else {
                print("Error: No se detect칩 entrada de audio")
                return
            }
            
            mic = input
            silence = Fader(mic, gain: 0)
            engine.output = silence
            
            pitchTap = PitchTap(mic) { [weak self] frequency, amplitude in
                guard let self = self else { return }
                self.processPitchData(frequency: frequency[0], amplitude: amplitude[0])
            }
            
            try engine.start()
            print("Motor de audio iniciado correctamente")
            
        } catch {
            print("Error en la inicializaci칩n del audio: \(error)")
        }
    }
    
    var microphonePermissionStatus: Bool {
        AVCaptureDevice.authorizationStatus(for: .audio) == .authorized
    }
    
    func start() {
        guard mic != nil else {
            print("Error: Input de audio no disponible")
            return
        }
        // Resetear valores al iniciar
        smoothedAmplitude = 0
        stabilityDuration = 0
        lastProcessedTime = Date()
        stabilityStartTime = nil
        lastStableFrequency = 0
        tunerData = .inactive
        
        pitchTap.start()
    }
    
    func stop() {
        pitchTap.stop()
        // Limpiar estados al detener
        DispatchQueue.main.async {
            self.tunerData = .inactive
            self.stabilityDuration = 0
        }
    }
}
